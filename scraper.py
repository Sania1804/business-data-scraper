# -*- coding: utf-8 -*-
"""internship.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nad3LuaLLZ5EvJYMVvpmRWQrWpdHNqt6
"""

#!pip install requests beautifulsoup4 selenium pandas

import requests
from bs4 import BeautifulSoup
import pandas as pd

def scrape_yellow_pages(url, headers=None):
    response = requests.get(url, headers=headers)
    if response.status_code == 200:
        soup = BeautifulSoup(response.text, 'html.parser')

        # Parse business entries
        data = []
        for business in soup.find_all('div', class_='result'):
            name = business.find('a', class_='business-name').text.strip() if business.find('a', class_='business-name') else None
            address = business.find('p', class_='adr').text.strip() if business.find('p', class_='adr') else None
            phone = business.find('div', class_='phones').text.strip() if business.find('div', class_='phones') else None
            data.append({
                'Name': name,
                'Address': address,
                'Phone': phone
            })

        return pd.DataFrame(data)
    else:
        print(f"Failed to fetch the webpage: {response.status_code}")
        return pd.DataFrame()

# Example usage
url = 'https://www.yellowpages.com/search?search_terms=plumber&geo_location_terms=New+York%2C+NY'
headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36'}
yellow_pages_data = scrape_yellow_pages(url, headers)


# Save to CSV
if not yellow_pages_data.empty:
    yellow_pages_data.to_csv('yellow_pages_data.csv', index=False)
    print("Data saved to yellow_pages_data.csv")

def clean_data(dataframe):
    print("Original Data:")
    print(dataframe.head())

    # Drop duplicate rows
    dataframe = dataframe.drop_duplicates()

    # Handle missing values
    dataframe = dataframe.fillna('Unknown')

    # Standardize phone numbers (example: remove non-digit characters)
    if 'Phone' in dataframe.columns:
        dataframe['Phone'] = dataframe['Phone'].str.replace(r'\D', '', regex=True)

    # Print cleaned data
    print("\nCleaned Data:")
    print(dataframe.head())

    return dataframe

# Usage example
if not yellow_pages_data.empty:
    cleaned_data = clean_data(yellow_pages_data)
    cleaned_data.to_csv('cleaned_yellow_pages_data.csv', index=False)
    print("Cleaned data saved to cleaned_yellow_pages_data.csv")
